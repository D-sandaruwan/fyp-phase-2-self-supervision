{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":848,"status":"ok","timestamp":1681351422685,"user":{"displayName":"Darshana Colab","userId":"07109758458813485529"},"user_tz":-330},"id":"hJBEw75MVK78"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","import scipy"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1681351444680,"user":{"displayName":"Darshana Colab","userId":"07109758458813485529"},"user_tz":-330},"id":"GzvaeMZUVK8A"},"outputs":[],"source":["def create_windows_np(data, window_size, stride):\n","    num_samples, num_channels = data.shape\n","    num_windows = (num_samples - window_size) // stride + 1\n","\n","    shape = (num_windows, window_size, num_channels)\n","    strides = (data.strides[0] * stride, data.strides[0], data.strides[1])\n","\n","    windows = np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n","\n","    return windows"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def noise_transform_vectorized(X, sigma=0.05):\n","    \"\"\"\n","    Adding random Gaussian noise with mean 0\n","    \"\"\"\n","    noise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n","    return X + noise\n","\n","def scaling_transform_vectorized(X, sigma=0.1):\n","    \"\"\"\n","    Scaling by a random factor\n","    \"\"\"\n","    scaling_factor = np.random.normal(loc=1.0, scale=sigma, size=(X.shape[0], 1, X.shape[2]))\n","    return X * scaling_factor\n","\n","def negate_transform_vectorized(X):\n","    \"\"\"\n","    Inverting the signals\n","    \"\"\"\n","    return X * -1\n","\n","def time_flip_transform_vectorized(X):\n","    \"\"\"\n","    Reversing the direction of time\n","    \"\"\"\n","    return X[:, ::-1, :]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Define the list of transformations to be applied\n","transformations = [\n","    lambda x: noise_transform_vectorized(x), \n","    lambda x: scaling_transform_vectorized(x),\n","    lambda x: negate_transform_vectorized(x),\n","    lambda x: time_flip_transform_vectorized(x),\n","    ]\n","transformations_names = [\"noise\", \"scale\", \"negate\", \"time_flip\"]"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":517,"status":"ok","timestamp":1681351609657,"user":{"displayName":"Darshana Colab","userId":"07109758458813485529"},"user_tz":-330},"id":"NfV-xrXJVK8C"},"outputs":[{"name":"stdout","output_type":"stream","text":["P001 100199 (500995, 200, 3)\n","P002 88199 (440995, 200, 3)\n","P003 97199 (485995, 200, 3)\n","P004 77916 (389580, 200, 3)\n","P005 98999 (494995, 200, 3)\n","P006 114299 (571495, 200, 3)\n","P007 100799 (503995, 200, 3)\n","P008 95854 (479270, 200, 3)\n","P009 73077 (365385, 200, 3)\n","P010 91799 (458995, 200, 3)\n"]}],"source":["path = \"../capture24\"\n","\n","user_dataset = {}\n","\n","for i in range(10):\n","    df = pd.read_csv(f'{path}/P{i+1:03d}.csv.gz', compression='gzip', low_memory=False)\n","    # assuming `df` is the pandas dataframe\n","    cols = ['x', 'y', 'z']\n","    data = df[cols].values.astype(np.float32)\n","\n","    user_id = f'P{i+1:03d}'\n","    user_data = create_windows_np(data, 200, 100)\n","\n","    # Get the number of windows and window size for the user's data\n","    num_windows, window_size, num_channels = user_data.shape\n","\n","    # Apply the transformations to the user's data\n","    transformed_data = np.concatenate([transform_fn(user_data) for transform_fn in transformations], axis=0)\n","    transformed_data = np.concatenate([transformed_data, user_data], axis=0)\n","\n","    # Create the labels for the transformed data\n","    transformed_labels = np.array(\n","        [\"Noise\" if transformation == \"noise\" else \n","         \"Scaling\" if transformation == \"scale\" else\n","         \"Negation\" if transformation == \"negate\" else \n","         \"Time Flip\" for transformation in transformations_names])\n","    transformed_labels = np.append(transformed_labels, \"Original\")\n","    transformed_labels = np.repeat(transformed_labels, num_windows)\n","\n","    transformed_user_data = {\n","        'X': transformed_data,\n","        'y': transformed_labels\n","    }\n","    file_path = f'{path}/{user_id}.obj'\n","    with open(file_path, 'wb') as file:\n","        pickle.dump(transformed_user_data, file)\n","\n","    # print(user_id, num_windows, transformed_data.shape, transformed_labels.shape)\n","    print(user_id, num_windows, transformed_data.shape)\n","    del transformed_user_data\n","    del transformed_data\n","    del transformed_labels\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["p001file = open(f'/media/darshana/Software/dataset/P001.obj', 'rb')\n","p001Dataset = pickle.load(p001file)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'X': array([[[-0.55305357, -0.51706906,  0.69314428],\n","        [-0.50472098, -0.56538143,  0.65664381],\n","        [-0.44077426, -0.53410961,  0.59784726],\n","        ...,\n","        [-0.47601569, -0.48092514,  0.68703596],\n","        [-0.46727538, -0.53516123,  0.74507716],\n","        [-0.43284447, -0.50125229,  0.6164534 ]],\n","\n","       [[-0.47427553, -0.53181389,  0.56354433],\n","        [-0.43548332, -0.6421605 ,  0.69263543],\n","        [-0.45257494, -0.47719815,  0.6296225 ],\n","        ...,\n","        [-0.49897984, -0.51259347,  0.61318453],\n","        [-0.42932175, -0.53151222,  0.64826092],\n","        [-0.47932165, -0.53827612,  0.61613918]],\n","\n","       [[-0.43956137, -0.50406777,  0.6121599 ],\n","        [-0.44457909, -0.50826508,  0.64317895],\n","        [-0.43738584, -0.51463917,  0.68245852],\n","        ...,\n","        [-0.42746603, -0.51584196,  0.71400161],\n","        [-0.48124537, -0.57680277,  0.71200579],\n","        [-0.42053982, -0.44312963,  0.61433704]],\n","\n","       ...,\n","\n","       [[ 0.0494156 , -0.79784578,  0.56569976],\n","        [ 0.03377215, -0.79784578,  0.56569976],\n","        [ 0.03377215, -0.79784578,  0.56569976],\n","        ...,\n","        [ 0.0494156 , -0.78228456,  0.56569976],\n","        [ 0.03377215, -0.78228456,  0.56569976],\n","        [ 0.03377215, -0.78228456,  0.56569976]],\n","\n","       [[ 0.0494156 , -0.79784578,  0.56569976],\n","        [ 0.03377215, -0.78228456,  0.56569976],\n","        [ 0.0494156 , -0.79784578,  0.55030459],\n","        ...,\n","        [ 0.03377215, -0.78228456,  0.56569976],\n","        [ 0.03377215, -0.79784578,  0.56569976],\n","        [ 0.0494156 , -0.78228456,  0.55030459]],\n","\n","       [[ 0.0494156 , -0.79784578,  0.56569976],\n","        [ 0.03377215, -0.78228456,  0.56569976],\n","        [ 0.03377215, -0.78228456,  0.56569976],\n","        ...,\n","        [ 0.0494156 , -0.78228456,  0.56569976],\n","        [ 0.0494156 , -0.78228456,  0.56569976],\n","        [ 0.0494156 , -0.78228456,  0.56569976]]]), 'y': array(['Noise', 'Noise', 'Noise', ..., 'Original', 'Original', 'Original'],\n","      dtype='<U9')}\n"]}],"source":["print(p001Dataset)\n","del p001Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv(f'{path}/P{i+1:03d}.csv.gz', compression='gzip', low_memory=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
